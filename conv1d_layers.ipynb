{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataX = np.load('train_data.npy')\n",
    "test_dataX = np.load('test_data.npy')\n",
    "train_datay = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Label\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         1\n",
      "4         0\n",
      "5         0\n",
      "6         1\n",
      "7         0\n",
      "8         1\n",
      "9         0\n",
      "10        0\n",
      "11        0\n",
      "12        1\n",
      "13        0\n",
      "14        0\n",
      "15        1\n",
      "16        1\n",
      "17        1\n",
      "18        0\n",
      "19        0\n",
      "20        1\n",
      "21        0\n",
      "22        0\n",
      "23        0\n",
      "24        0\n",
      "25        1\n",
      "26        0\n",
      "27        0\n",
      "28        0\n",
      "29        1\n",
      "...     ...\n",
      "3969      0\n",
      "3970      0\n",
      "3971      0\n",
      "3972      0\n",
      "3973      0\n",
      "3974      0\n",
      "3975      0\n",
      "3976      0\n",
      "3977      1\n",
      "3978      0\n",
      "3979      1\n",
      "3980      0\n",
      "3981      0\n",
      "3982      0\n",
      "3983      0\n",
      "3984      1\n",
      "3985      0\n",
      "3986      0\n",
      "3987      0\n",
      "3988      0\n",
      "3989      1\n",
      "3990      1\n",
      "3991      0\n",
      "3992      0\n",
      "3993      0\n",
      "3994      0\n",
      "3995      0\n",
      "3996      0\n",
      "3997      0\n",
      "3998      0\n",
      "\n",
      "[3999 rows x 1 columns]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_datay = train_datay.drop('Id',1)\n",
    "train_dataX = train_dataX.reshape(-1,210,210)\n",
    "test_dataX = test_dataX.reshape(-1,210,210)\n",
    "Y_train = np_utils.to_categorical(train_datay,2)\n",
    "print(train_datay)\n",
    "\n",
    "print(Y_train)\n",
    "\n",
    "#splitting data for validation\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train_dataX,Y_train, test_size=0.4, shuffle=True)\n",
    "\n",
    "#deleting unwanted variables\n",
    "#del train_dataX, train_datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16 ,kernel_size=3 ,activation='relu' ,input_shape=(210,210)))\n",
    "model.add(Conv1D(16, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(32, kernel_size=3,activation='relu'))\n",
    "model.add(Conv1D(32, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu'))\n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "sgd=optimizers.SGD(lr=.1)\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = model.fit(train_dataX, Y_train,\n",
    "          batch_size=500, nb_epoch=15,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict_classes(test_dataX)\n",
    "print(Y_test_pred)\n",
    "\n",
    "roc = roc_auc_score(y_test, Y_test_pred)\n",
    "print(\"ROC:\" + str(round(roc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#Checking entire validation\n",
    "testing_X = model.predict_classes(train_dataX)\n",
    "print(accuracy_score(train_datay, testing_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict_proba(test_dataX)\n",
    "print(Y_test_pred)\n",
    "\n",
    "Y_test_predClass = model.predict_proba(test_dataX)\n",
    "print(Y_test_predClass)\n",
    "\n",
    "roc = roc_auc_score(y_test, Y_test_pred)\n",
    "print(\"ROC:\" + str(round(roc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.rint(Y_test_predClass)).to_csv('submission19.csv', header=[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.rint(Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************************************************************************************\n",
    "**Using Logistic regression to classify audio labels. Using the code provided in class**\n",
    "****************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataX = np.load('train_data.npy')\n",
    "test_dataX = np.load('test_data.npy')\n",
    "train_datay = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing data\n",
    "train_datay = train_datay.drop('Id',1)\n",
    "train_dataX = train_dataX.reshape(-1,44100)\n",
    "test_dataX = test_dataX.reshape(-1,44100)\n",
    "Y_train = np_utils.to_categorical(train_datay,2)\n",
    "\n",
    "#splitting data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataX,Y_train, test_size=0.1, shuffle=True)\n",
    "\n",
    "#deleting unwanted variables\n",
    "del train_dataX, train_datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(2,activation='softmax',input_shape=(44100,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "sgd=optimizers.SGD(lr=.1)\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = model.fit(X_train, y_train,\n",
    "          batch_size=500, nb_epoch=10,verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict_proba(test_dataX)\n",
    "print(Y_test_pred)\n",
    "\n",
    "Y_test_predClass = model.predict_proba(test_dataX)\n",
    "print(Y_test_predClass)\n",
    "\n",
    "roc = roc_auc_score(y_test, Y_test_pred)\n",
    "print(\"ROC:\" + str(round(roc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame((Y_test_pred[:,0])).to_csv('submission6.csv', header=[\"Label\"])\n",
    "pd.DataFrame((Y_test_pred[:,1])).to_csv('submission6.csv', header=[\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************************************************************************************\n",
    "***********************************************************************************************\n",
    "**Using same model but changing the optimizer to be Adam instead of stochastic gradient descent**\n",
    "***********************************************************************************************\n",
    "***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "train_dataX = np.load('train_data.npy')\n",
    "test_dataX = np.load('test_data.npy')\n",
    "train_datay = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing data\n",
    "train_datay = train_datay.drop('Id',1)\n",
    "train_dataX = train_dataX.reshape(-1,210,210)\n",
    "test_dataX = test_dataX.reshape(-1,210,210)\n",
    "Y_train = np_utils.to_categorical(train_datay,2)\n",
    "\n",
    "#splitting data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataX,Y_train, test_size=0.2, shuffle=True)\n",
    "\n",
    "#deleting unwanted variables\n",
    "\n",
    "del train_dataX, train_datay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32 ,kernel_size=9 ,activation='relu' ,input_shape=(210,210)))\n",
    "model.add(Conv1D(32, kernel_size=9,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=16))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu'))\n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=500, nb_epoch=10,verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict_proba(test_dataX)\n",
    "print(Y_test_pred)\n",
    "\n",
    "Y_test_predClass = model.predict_proba(test_dataX)\n",
    "print(Y_test_predClass)\n",
    "\n",
    "roc = roc_auc_score(y_test, Y_test_pred)\n",
    "print(\"ROC:\" + str(round(roc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_predClass = model.predict(test_dataX)\n",
    "print(Y_test_predClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Y_test_predClass).to_csv('submission27.csv', header=[\"Label\", \"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************************************************************************************\n",
    "***********************************************************************************************\n",
    "**Scaling data**\n",
    "***********************************************************************************************\n",
    "***********************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "train_dataX = np.load('train_data.npy')\n",
    "test_dataX = np.load('test_data.npy')\n",
    "train_datay = pd.read_csv('train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing data\n",
    "\n",
    "train_dataX /= 256\n",
    "test_dataX /= 256\n",
    "\n",
    "train_datay = train_datay.drop('Id',1)\n",
    "train_dataX = train_dataX.reshape(-1,210,210)\n",
    "test_dataX = test_dataX.reshape(-1,210,210)\n",
    "Y_train = np_utils.to_categorical(train_datay,2)\n",
    "\n",
    "#splitting data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataX,Y_train, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, solution\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32 ,kernel_size=3 ,activation='relu' ,input_shape=(210,210)))\n",
    "model.add(Conv1D(32, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu'))\n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = model.fit(X_train, y_train,\n",
    "          batch_size=500, nb_epoch=15,verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#Checking entire validation\n",
    "testing_X = model.predict_classes(X_train)\n",
    "print(accuracy_score(y_train[:,1], testing_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict_proba(test_dataX)\n",
    "print(Y_test_pred)\n",
    "\n",
    "Y_test_predClass = model.predict_proba(test_dataX)\n",
    "print(Y_test_predClass)\n",
    "\n",
    "roc = roc_auc_score(y_test, Y_test_pred)\n",
    "print(\"ROC:\" + str(round(roc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Y_test_predClass[:,0]).to_csv('submission26.csv', header=[\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More layes adding into previous architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "train_dataX = np.load('augmentedData_Combined.npy')\n",
    "test_dataX = np.load('test_data.npy')\n",
    "train_datay = pd.read_csv('AugmentedCombined_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing data\n",
    "train_dataX /= 256\n",
    "test_dataX /= 256\n",
    "\n",
    "train_datay = train_datay.drop('Id',1)\n",
    "train_dataX = train_dataX.reshape(-1,210,210)\n",
    "test_dataX = test_dataX.reshape(-1,210,210)\n",
    "Y_train = np_utils.to_categorical(train_datay,2)\n",
    "\n",
    "#splitting data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataX,Y_train, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling1D, BatchNormalization\n",
    "del model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(16 ,kernel_size=3 ,activation='relu' ,input_shape=(210,210)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(32, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "'''\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "'''\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.01)\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = model.fit(X_train, y_train,\n",
    "          batch_size=500, nb_epoch=70,verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict_proba(X_test)\n",
    "print(Y_test_pred)\n",
    "\n",
    "roc = roc_auc_score(y_test, Y_test_pred)\n",
    "print(\"ROC:\" + str(round(roc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_predClass = model.predict_proba(test_dataX)\n",
    "print(Y_test_predClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Y_test_predClass[:,0]).to_csv('submission56.csv', header=[\"Label\"], index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with augmented data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataX = np.load('augmented_data.npy')\n",
    "test_dataX = np.load('test_data.npy')\n",
    "train_datay = pd.read_csv('Augmented_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing data\n",
    "train_datay = train_datay.drop('Id',1)\n",
    "train_dataX = train_dataX.reshape(-1,210,210)\n",
    "test_dataX = test_dataX.reshape(-1,210,210)\n",
    "Y_train = np_utils.to_categorical(train_datay,2)\n",
    "\n",
    "#splitting data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataX,Y_train, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(16 ,kernel_size=6 ,activation='relu' ,input_shape=(210,210)))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(32, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(128, kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=500, nb_epoch=20,verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_pred = model.predict_proba(test_dataX)\n",
    "print(Y_test_pred)\n",
    "\n",
    "Y_test_predClass = model.predict_proba(test_dataX)\n",
    "print(Y_test_predClass)\n",
    "\n",
    "roc = roc_auc_score(y_test, Y_test_pred)\n",
    "print(\"ROC:\" + str(round(roc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Y_test_predClass[:,0]).to_csv('submission37.csv', header=[\"Label\"], index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with augmented data - part 2**                                                                                   \n",
    "Using part 2 of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataX = np.load('augmentedData_Combined.npy')\n",
    "test_dataX = np.load('test_data.npy')\n",
    "train_datay = pd.read_csv('AugmentedCombined_labels.csv')\n",
    "\n",
    "#train_dataX = np.load('augmented_data2.npy')\n",
    "#test_dataX = np.load('test_data.npy')\n",
    "#train_datay = pd.read_csv('Augmented_labels2.csv')\n",
    "\n",
    "#train_dataX = np.load('augmented_data.npy')\n",
    "#test_dataX = np.load('test_data.npy')\n",
    "#train_datay = pd.read_csv('Augmented_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing data\n",
    "train_datay = train_datay.drop('Id',1)\n",
    "#train_dataX = train_dataX.reshape(-1,150,294)\n",
    "#test_dataX = test_dataX.reshape(-1,150,294)\n",
    "#train_dataX = train_dataX.reshape(-1,100,441)\n",
    "#test_dataX = test_dataX.reshape(-1,100,441)\n",
    "train_dataX = train_dataX.reshape(-1,210,210)\n",
    "test_dataX = test_dataX.reshape(-1,210,210)\n",
    "Y_train = np_utils.to_categorical(train_datay,2)\n",
    "\n",
    "#splitting data for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_dataX,Y_train, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = Sequential() \n",
    "#model.add(Conv1D(16 ,kernel_size=3 ,activation='relu' ,input_shape=(150,294))) \n",
    "#model.add(Conv1D(16 ,kernel_size=3 ,activation='relu' ,input_shape=(100,441))) \n",
    "model.add(Conv1D(16 ,kernel_size=3 ,activation='relu' ,input_shape=(210,210))) \n",
    "model.add(MaxPooling1D(pool_size=2)) \n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Conv1D(32, kernel_size=3,activation='relu')) \n",
    "model.add(MaxPooling1D(pool_size=2)) \n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Conv1D(64, kernel_size=3,activation='relu')) \n",
    "model.add(MaxPooling1D(pool_size=2)) \n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Conv1D(128, kernel_size=3,activation='relu')) \n",
    "model.add(MaxPooling1D(pool_size=2)) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(1024,activation='relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "#model.add(Dense(1024,activation='relu')) \n",
    "#model.add(Dropout(0.25)) \n",
    "#model.add(Dense(256,activation='relu')) \n",
    "#model.add(Dropout(0.25)) \n",
    "model.add(Dense(64,activation='relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(32,activation='relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(2,activation='softmax')) \n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=100, nb_epoch=100,verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "Y_test_predClass = model.predict_proba(X_test)\n",
    "\n",
    "roc = roc_auc_score(y_test, Y_test_predClass)\n",
    "print(\"ROC:\" + str(round(roc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_predClass = model.predict_proba(test_dataX)\n",
    "print(Y_test_predClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Y_test_predClass[:,0]).to_csv('submission55.csv', header=[\"Label\"], index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
